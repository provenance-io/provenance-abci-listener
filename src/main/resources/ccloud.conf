# Grpc server config
grpc.server {
  addr = localhost
  port = 1234
}

# Kafka producer config
kafka.producer {
  # Assign a topic name and an optional prefix where events will be written.
  listen-topics {
    prefix = "local-"
    listen-begin-block = ${?kafka.producer.listen-topics.prefix}"listen-begin-block"
    listen-end-block = ${?kafka.producer.listen-topics.prefix}"listen-end-block"
    listen-deliver-tx = ${?kafka.producer.listen-topics.prefix}"listen-deliver-tx"
    listen-commit = ${?kafka.producer.listen-topics.prefix}"listen-commit"
  }

  # Properties defined by org.apache.kafka.clients.producer.ProducerConfig.
  # can be defined in this configuration section.
  kafka-clients {
    bootstrap.servers = "{{ BROKER_ENDPOINT }}"
    acks = all
    enable.idempotence = true
    max.in.flight.requests.per.connection = 1
    linger.ms = 50
    max.request.size = 204857600
    key.serializer = org.apache.kafka.common.serialization.StringSerializer
    value.serializer = io.provenance.abci.listener.ProtobufSerializer

    # Required connection configs for Confluent Cloud
    ssl.endpoint.identification.algorithm=https
    sasl.mechanism=PLAIN
    sasl.jaas.config="org.apache.kafka.common.security.plain.PlainLoginModule required username=\"{{ CLOUD_API_KEY }}\" password=\"{{ CLOUD_API_SECRET }}\";"
    security.protocol=SASL_SSL

    # Best practice for higher availability in Apache Kafka clients prior to 3.0
    session.timeout.ms=45000

    request.timeout.ms = 20000
    retry.backoff.ms = 500

    # Required connection configs for Confluent Cloud Schema Registry
    schema.registry.url="https://{{ SR_ENDPOINT }}"
    basic.auth.credentials.source=USER_INFO
    basic.auth.user.info="{{ SR_API_KEY }}:{{ SR_API_SECRET }}"
  }
}